{"cells":[{"cell_type":"markdown","source":["#### Tutorial 3- Pyspark With Python-Pyspark DataFrames- Handling Missing Values\n#### Pyspak Handling missing values\n- Dropping Columns\n- Dropping Rows\n- Various Parameter In Dropping functionalities\n- Handling Missing values by Mean, Median and Mode"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2cbc802-6856-416c-99c6-adda53ca1c22"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('Practice').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cf62105-ec06-4b68-99b1-517541f74cae"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pyspark = spark.read.csv('/FileStore/tables/test_data-2.csv', header=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4fc35ef7-3f02-4bdf-b057-5b190876611a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pyspark.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b24b92c0-4ee1-454a-a97e-85bd669869c4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+----+----------+------+\n|     Name| Age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 10000|\n|  Sushant|  23|         5| 20000|\n|Dadasaheb|  24|         5| 30000|\n|    Rahul|  22|         3| 30000|\n|    Sagar|  22|         4| 25000|\n|    Suraj|  23|         4|  null|\n|  Ranjeet|  23|         2| 22000|\n|   Pramod|  23|         3| 45000|\n|    Bhima|  24|         3| 90000|\n|      Ram|null|      null|  null|\n|     null|  21|         7|  null|\n+---------+----+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+----+----------+------+\n|     Name| Age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 10000|\n|  Sushant|  23|         5| 20000|\n|Dadasaheb|  24|         5| 30000|\n|    Rahul|  22|         3| 30000|\n|    Sagar|  22|         4| 25000|\n|    Suraj|  23|         4|  null|\n|  Ranjeet|  23|         2| 22000|\n|   Pramod|  23|         3| 45000|\n|    Bhima|  24|         3| 90000|\n|      Ram|null|      null|  null|\n|     null|  21|         7|  null|\n+---------+----+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.drop('Name').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cde5547b-c5b5-4d0c-8f6f-e3458e4376f5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+----------+------+\n| Age|Experience|Salary|\n+----+----------+------+\n|  31|        10| 10000|\n|  23|         5| 20000|\n|  24|         5| 30000|\n|  22|         3| 30000|\n|  22|         4| 25000|\n|  23|         4|  null|\n|  23|         2| 22000|\n|  23|         3| 45000|\n|  24|         3| 90000|\n|null|      null|  null|\n|  21|         7|  null|\n+----+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+----------+------+\n| Age|Experience|Salary|\n+----+----------+------+\n|  31|        10| 10000|\n|  23|         5| 20000|\n|  24|         5| 30000|\n|  22|         3| 30000|\n|  22|         4| 25000|\n|  23|         4|  null|\n|  23|         2| 22000|\n|  23|         3| 45000|\n|  24|         3| 90000|\n|null|      null|  null|\n|  21|         7|  null|\n+----+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62b867be-8c0c-4fb4-97a2-c281f458e405"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+----+----------+------+\n|     Name| Age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 10000|\n|  Sushant|  23|         5| 20000|\n|Dadasaheb|  24|         5| 30000|\n|    Rahul|  22|         3| 30000|\n|    Sagar|  22|         4| 25000|\n|    Suraj|  23|         4|  null|\n|  Ranjeet|  23|         2| 22000|\n|   Pramod|  23|         3| 45000|\n|    Bhima|  24|         3| 90000|\n|      Ram|null|      null|  null|\n|     null|  21|         7|  null|\n+---------+----+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+----+----------+------+\n|     Name| Age|Experience|Salary|\n+---------+----+----------+------+\n|    Krish|  31|        10| 10000|\n|  Sushant|  23|         5| 20000|\n|Dadasaheb|  24|         5| 30000|\n|    Rahul|  22|         3| 30000|\n|    Sagar|  22|         4| 25000|\n|    Suraj|  23|         4|  null|\n|  Ranjeet|  23|         2| 22000|\n|   Pramod|  23|         3| 45000|\n|    Bhima|  24|         3| 90000|\n|      Ram|null|      null|  null|\n|     null|  21|         7|  null|\n+---------+----+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["## You can use na attribute of pyspark dataframe to handle null values, na has different functions like drop, fill, replace...\nnew_df = df_pyspark.na.drop() # It will drop all the rows having null values\nnew_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cb223ee-8744-4631-b478-ef1d1c703fd4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n+---------+---+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n+---------+---+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["new_df = df_pyspark.na.drop(how='any') # Here how specifies how we want to delete those null. if its value is any then it drops entire row having null\nnew_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2847c59c-99f8-4cfc-89bf-3f690a0e28b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n+---------+---+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n+---------+---+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# there is one more option called threshold. If there are more non nulls than what threshold value is specified then it will delete entire row\n\ndf_pyspark.na.drop(how='any', thresh=3).show() # here record suraj, 23, 4, null kept other droped , as it have more than 3 not null values\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e597f226-5442-4bcc-afd1-0420f3692de8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|    Suraj| 23|         4|  null|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n+---------+---+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|    Suraj| 23|         4|  null|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n+---------+---+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["### subset parameter\ndf_pyspark.na.drop(how='any', subset=['Experience']).show() # in subset it will delete a row having null in specified column\n# Here in above exapmle it will check nulls in 'Experience' column and delete entire row"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40efecf8-090b-4fbf-af59-0f13f2a9a200"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|    Suraj| 23|         4|  null|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n|     null| 21|         7|  null|\n+---------+---+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+------+\n|     Name|Age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 10000|\n|  Sushant| 23|         5| 20000|\n|Dadasaheb| 24|         5| 30000|\n|    Rahul| 22|         3| 30000|\n|    Sagar| 22|         4| 25000|\n|    Suraj| 23|         4|  null|\n|  Ranjeet| 23|         2| 22000|\n|   Pramod| 23|         3| 45000|\n|    Bhima| 24|         3| 90000|\n|     null| 21|         7|  null|\n+---------+---+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["### Filling the missing values.\nnew_df = df_pyspark.na.fill('Missing Values')\nnew_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08d5b040-a01b-4ddd-ac19-c16612e435db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------+--------------+--------------+--------------+\n|          Name|           Age|    Experience|        Salary|\n+--------------+--------------+--------------+--------------+\n|         Krish|            31|            10|         10000|\n|       Sushant|            23|             5|         20000|\n|     Dadasaheb|            24|             5|         30000|\n|         Rahul|            22|             3|         30000|\n|         Sagar|            22|             4|         25000|\n|         Suraj|            23|             4|Missing Values|\n|       Ranjeet|            23|             2|         22000|\n|        Pramod|            23|             3|         45000|\n|         Bhima|            24|             3|         90000|\n|           Ram|Missing Values|Missing Values|Missing Values|\n|Missing Values|            21|             7|Missing Values|\n+--------------+--------------+--------------+--------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------+--------------+--------------+--------------+\n|          Name|           Age|    Experience|        Salary|\n+--------------+--------------+--------------+--------------+\n|         Krish|            31|            10|         10000|\n|       Sushant|            23|             5|         20000|\n|     Dadasaheb|            24|             5|         30000|\n|         Rahul|            22|             3|         30000|\n|         Sagar|            22|             4|         25000|\n|         Suraj|            23|             4|Missing Values|\n|       Ranjeet|            23|             2|         22000|\n|        Pramod|            23|             3|         45000|\n|         Bhima|            24|             3|         90000|\n|           Ram|Missing Values|Missing Values|Missing Values|\n|Missing Values|            21|             7|Missing Values|\n+--------------+--------------+--------------+--------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["### Filling the missing values.\nnew_df = df_pyspark.na.fill('Missing Values', ['Experience','Age'])\nnew_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52ff5c99-12e9-49c9-bfb9-37df9c211a2c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+--------------+--------------+------+\n|     Name|           Age|    Experience|Salary|\n+---------+--------------+--------------+------+\n|    Krish|            31|            10| 10000|\n|  Sushant|            23|             5| 20000|\n|Dadasaheb|            24|             5| 30000|\n|    Rahul|            22|             3| 30000|\n|    Sagar|            22|             4| 25000|\n|    Suraj|            23|             4|  null|\n|  Ranjeet|            23|             2| 22000|\n|   Pramod|            23|             3| 45000|\n|    Bhima|            24|             3| 90000|\n|      Ram|Missing Values|Missing Values|  null|\n|     null|            21|             7|  null|\n+---------+--------------+--------------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+--------------+--------------+------+\n|     Name|           Age|    Experience|Salary|\n+---------+--------------+--------------+------+\n|    Krish|            31|            10| 10000|\n|  Sushant|            23|             5| 20000|\n|Dadasaheb|            24|             5| 30000|\n|    Rahul|            22|             3| 30000|\n|    Sagar|            22|             4| 25000|\n|    Suraj|            23|             4|  null|\n|  Ranjeet|            23|             2| 22000|\n|   Pramod|            23|             3| 45000|\n|    Bhima|            24|             3| 90000|\n|      Ram|Missing Values|Missing Values|  null|\n|     null|            21|             7|  null|\n+---------+--------------+--------------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import Imputer\nimputer = Imputer(\ninputCols = ['age', 'Experience', 'Salary'],\n  outputCols = [\"{}_imputed\".format(c) for c in ['age', 'Experience','Salary']]\n).setStratergy('mean')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aaf01488-7248-4d2e-b120-d9c02857bfb4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-796033921745465>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeature\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mImputer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m imputer = Imputer(\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0minputCols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'age'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Experience'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Salary'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m   \u001B[0moutputCols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"{}_imputed\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'age'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Experience'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'Salary'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m ).setStratergy('mean')\n\n\u001B[0;31mAttributeError\u001B[0m: 'Imputer' object has no attribute 'setStratergy'","errorSummary":"<span class='ansi-red-fg'>AttributeError</span>: 'Imputer' object has no attribute 'setStratergy'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-796033921745465>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mml\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeature\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mImputer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m imputer = Imputer(\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0minputCols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'age'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Experience'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Salary'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m   \u001B[0moutputCols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"{}_imputed\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'age'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Experience'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'Salary'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m ).setStratergy('mean')\n\n\u001B[0;31mAttributeError\u001B[0m: 'Imputer' object has no attribute 'setStratergy'"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8de61f42-101b-4eb3-be24-7634c32389f7"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"kn_pyspark_test_3","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":360479827233404}},"nbformat":4,"nbformat_minor":0}
