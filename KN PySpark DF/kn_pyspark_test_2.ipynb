{"cells":[{"cell_type":"markdown","source":["#### Tutorial 2-Pyspark With Python-Pyspark DataFrames- Part 1\n#### In this session we will cover\n- PySpark DataFrame\n- Reading the Dataset\n- Checking the Datatypes of the column(Schema)\n- Selecting Columns And Indexing\n- Check Describe option smilar to pandas\n- Adding columns\n- Dropping columns\n- Renaming columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e20843b-91df-4461-b030-d83672b1710e"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd702d35-6c7b-45c3-bcd0-6f537b7dfc3e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.appName('DataFrame').getOrCreate()\nprint(spark)\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57ae89f2-6e3b-4b0c-bcff-0c2a3925604f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<pyspark.sql.session.SparkSession object at 0x7fe1ff58d790>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["<pyspark.sql.session.SparkSession object at 0x7fe1ff58d790>\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1281776841989101#setting/sparkui/0328-020702-2rf0xqsk/driver-7517944183348477457\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1281776841989101#setting/sparkui/0328-020702-2rf0xqsk/driver-7517944183348477457\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["### Read the dataset\ndf_pyspark = spark.read.option('header','true').csv('/FileStore/tables/test_data-1.csv')\ndf_pyspark.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"812ef093-10b1-49b3-84f7-27ed9e76623d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["  ### Check the schema\n  df_pyspark.printSchema()\n  ### here you can see all the column datatype is string, but it should not be the case, you can see new dataset reading in below cell :)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2121674-b6c4-4b23-8590-dbb52a785c24"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Name: string (nullable = true)\n |-- Age: string (nullable = true)\n |-- Experience: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Name: string (nullable = true)\n |-- Age: string (nullable = true)\n |-- Experience: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df_pyspark = spark.read.option('header','true').csv('/FileStore/tables/test_data-1.csv', inferSchema=True) \n# here you can see I have passed one more parameter in csv function as inferSchema=True that means it decides column datatype from the values from csv file\ndf_pyspark.printSchema() #printing the schema and check datatypeee :)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b213fce-4bab-4bb4-83cf-d447d52e99c6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Name: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Experience: integer (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Name: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Experience: integer (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# we can do above two things like header and inferschema in csv function only as below\ndf_pyspark = spark.read.csv('/FileStore/tables/test_data-1.csv', header=True, inferSchema=True)\nprint(df_pyspark.printSchema())  # To show schema of dataframe\nprint(df_pyspark.show())         # To show actual data from dataframe "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ace059b-2057-4042-bbdc-cc907730234e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Name: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Experience: integer (nullable = true)\n\nNone\n+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\nNone\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Name: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Experience: integer (nullable = true)\n\nNone\n+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\nNone\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Lets check the type of df_pyspark dataframe\nprint(type(df_pyspark))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf3b10fc-c3f3-46e9-bb1f-5e33d2fcbd47"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<class 'pyspark.sql.dataframe.DataFrame'>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["<class 'pyspark.sql.dataframe.DataFrame'>\n"]}}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.columns # columns property of pyspark dataframe returns list of what all columns are there in dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4ffde52-6fef-4c0a-860e-9348127ac6a6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: ['Name', 'Age', 'Experience']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: ['Name', 'Age', 'Experience']"]}}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.head(2) # head function of pyspark dataframe returns the no of first rows "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ffa3ac7-d432-456b-98f6-5472ad403acb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[15]: [Row(Name='Krish', Age=31, Experience=10),\n Row(Name='Sushant', Age=23, Experience=5)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[15]: [Row(Name='Krish', Age=31, Experience=10),\n Row(Name='Sushant', Age=23, Experience=5)]"]}}],"execution_count":0},{"cell_type":"code","source":["pf_pyspark.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38c4845b-2ab8-4c0d-8908-67f70a29ef98"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["name_df = df_pyspark.select('Name') # the select function of pyspark dataframe take column name and returns the specified colunn dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41ea5523-caf6-427a-873a-236fed2cb811"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["name_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cee61eb-7ab6-4582-aef3-6b7d05a3539e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+\n|     Name|\n+---------+\n|    Krish|\n|  Sushant|\n|Dadasaheb|\n|    Rahul|\n|    Sagar|\n|    Suraj|\n|  Ranjeet|\n|   Pramod|\n|    Bhima|\n+---------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+\n|     Name|\n+---------+\n|    Krish|\n|  Sushant|\n|Dadasaheb|\n|    Rahul|\n|    Sagar|\n|    Suraj|\n|  Ranjeet|\n|   Pramod|\n|    Bhima|\n+---------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#what if I want to give multiple column names\nnew_df = df_pyspark.select(['Name','Experience'])\nprint(new_df.show())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb4fcb65-30a4-46b3-bb90-1f6f9b3288a3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+----------+\n|     Name|Experience|\n+---------+----------+\n|    Krish|        10|\n|  Sushant|         5|\n|Dadasaheb|         5|\n|    Rahul|         3|\n|    Sagar|         4|\n|    Suraj|         4|\n|  Ranjeet|         2|\n|   Pramod|         3|\n|    Bhima|         3|\n+---------+----------+\n\nNone\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+----------+\n|     Name|Experience|\n+---------+----------+\n|    Krish|        10|\n|  Sushant|         5|\n|Dadasaheb|         5|\n|    Rahul|         3|\n|    Sagar|         4|\n|    Suraj|         4|\n|  Ranjeet|         2|\n|   Pramod|         3|\n|    Bhima|         3|\n+---------+----------+\n\nNone\n"]}}],"execution_count":0},{"cell_type":"code","source":["df_pyspark.dtypes # pyspark datafraem has one attribute named dtypes which returns the list of datatypes of all columns of dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18213dee-0117-4674-b161-7ded3dbeb84d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[25]: [('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[25]: [('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"]}}],"execution_count":0},{"cell_type":"code","source":["# Describe :- pyspark dataframe also has function called describe() like pandas which returns all description like mean, median, mode,... of df\ndf_describe = df_pyspark.describe() # describe fucntion returns a new dataframe of description like mean, median mode, sd,..\ndf_describe.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98c52233-964c-4b2b-afe2-5814fa050ef9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+-------+-----------------+-----------------+\n|summary|   Name|              Age|       Experience|\n+-------+-------+-----------------+-----------------+\n|  count|      9|                9|                9|\n|   mean|   null|23.88888888888889|4.333333333333333|\n| stddev|   null|2.758824226207808|2.345207879911715|\n|    min|  Bhima|               22|                2|\n|    max|Sushant|               31|               10|\n+-------+-------+-----------------+-----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+-------+-----------------+-----------------+\n|summary|   Name|              Age|       Experience|\n+-------+-------+-----------------+-----------------+\n|  count|      9|                9|                9|\n|   mean|   null|23.88888888888889|4.333333333333333|\n| stddev|   null|2.758824226207808|2.345207879911715|\n|    min|  Bhima|               22|                2|\n|    max|Sushant|               31|               10|\n+-------+-------+-----------------+-----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["### Adding new column to dataframe\nnew_df = df_pyspark.withColumn('Experience after 2 yrs',df_pyspark['Experience']+2)\nnew_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c113651-1f6c-4a01-84ea-973c3f24a932"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+----------------------+\n|     Name|Age|Experience|Experience after 2 yrs|\n+---------+---+----------+----------------------+\n|    Krish| 31|        10|                    12|\n|  Sushant| 23|         5|                     7|\n|Dadasaheb| 24|         5|                     7|\n|    Rahul| 22|         3|                     5|\n|    Sagar| 22|         4|                     6|\n|    Suraj| 23|         4|                     6|\n|  Ranjeet| 23|         2|                     4|\n|   Pramod| 23|         3|                     5|\n|    Bhima| 24|         3|                     5|\n+---------+---+----------+----------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+----------------------+\n|     Name|Age|Experience|Experience after 2 yrs|\n+---------+---+----------+----------------------+\n|    Krish| 31|        10|                    12|\n|  Sushant| 23|         5|                     7|\n|Dadasaheb| 24|         5|                     7|\n|    Rahul| 22|         3|                     5|\n|    Sagar| 22|         4|                     6|\n|    Suraj| 23|         4|                     6|\n|  Ranjeet| 23|         2|                     4|\n|   Pramod| 23|         3|                     5|\n|    Bhima| 24|         3|                     5|\n+---------+---+----------+----------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["## Drop the column\nnew_df = df_pyspark.drop('Experience after 2 yrs')\nnew_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9839c7a9-6a1d-4a1a-b985-acae5204a0bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+\n|     Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[" ### Rename the column\nrenamed_df = df_pyspark.withColumnRenamed('Name','New Name')\nrenamed_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83bf4bf4-d95c-4843-83ac-fa602727c0d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+----------+\n| New Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+----------+\n| New Name|Age|Experience|\n+---------+---+----------+\n|    Krish| 31|        10|\n|  Sushant| 23|         5|\n|Dadasaheb| 24|         5|\n|    Rahul| 22|         3|\n|    Sagar| 22|         4|\n|    Suraj| 23|         4|\n|  Ranjeet| 23|         2|\n|   Pramod| 23|         3|\n|    Bhima| 24|         3|\n+---------+---+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2b864ba-d7e2-455c-8070-d4bcca004052"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"kn_pyspark_test_2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3349810159273421}},"nbformat":4,"nbformat_minor":0}
