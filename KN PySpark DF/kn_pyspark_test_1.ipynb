{"cells":[{"cell_type":"markdown","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"PySpark DataFrames Basic Introduction","showTitle":true,"inputWidgets":{},"nuid":"e86af5e2-4e99-4766-a0fb-eee9210695f8"}}},{"cell_type":"markdown","source":["#### Tutorial 1-Pyspark With Python-Pyspark Introduction and Installation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e08988ed-e11f-423c-8a31-4cbf91e59bdb"}}},{"cell_type":"code","source":["import pandas as pd\nfrom pyspark.sql import SparkSession #first we need to import sparksession"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12f9aa59-6d6b-4142-b908-749aa28f4f49"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.appName('Practice').getOrCreate() # first we need to create sparksession "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6cd8d04-fad6-42c1-856b-bf12191e8b3f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pyspark = spark.read.csv('/FileStore/tables/test_data.csv')  # read csv file and convert that into pyspark dataframe\nprint(df_pyspark)                                               # printing schema of pysparkdataframe\nprint(df_pyspark.show())                                        # showing actual data from pyspark dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75ce51c9-6004-4ed0-9d06-1f8d6793a774"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"DataFrame[_c0: string, _c1: string]\n+---------+---+\n|      _c0|_c1|\n+---------+---+\n|     Name|Age|\n|    Krish| 31|\n|  Sushant| 23|\n|Dadasaheb| 24|\n+---------+---+\n\nNone\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["DataFrame[_c0: string, _c1: string]\n+---------+---+\n|      _c0|_c1|\n+---------+---+\n|     Name|Age|\n|    Krish| 31|\n|  Sushant| 23|\n|Dadasaheb| 24|\n+---------+---+\n\nNone\n"]}}],"execution_count":0},{"cell_type":"code","source":["df_pyspark = spark.read.option('header','true').csv('/FileStore/tables/test_data.csv') # Here first line of csv file will be considered as main header"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4dbe623-212f-46c6-b680-0a450e77d714"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pyspark.show() #To show contents from the pyspark dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de281f0e-f46c-435a-944c-acbb3dbfa61d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---+\n|     Name|Age|\n+---------+---+\n|    Krish| 31|\n|  Sushant| 23|\n|Dadasaheb| 24|\n+---------+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---+\n|     Name|Age|\n+---------+---+\n|    Krish| 31|\n|  Sushant| 23|\n|Dadasaheb| 24|\n+---------+---+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["print(df_pyspark.printSchema()) #printschema method of df will print the schema of df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f77c1bc-4f5e-4707-9ac8-698def52aaf6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Name: string (nullable = true)\n |-- Age: string (nullable = true)\n\nNone\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Name: string (nullable = true)\n |-- Age: string (nullable = true)\n\nNone\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08699062-c20a-4f0d-856c-bc3120b7b41f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"kn_pyspark_test_1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3349810159273411}},"nbformat":4,"nbformat_minor":0}
